
import axios from "axios";

// Interface matching the OpenAI analysis result
interface CodeAnalysisResult {
  score: number;
  securityIssues: Record<string, any>[];
  performanceIssues: Record<string, any>[];
  maintainabilityIssues: Record<string, any>[];
  summary: string;
}

// Create a Groq API client for accessing Mistral 7B
class GroqClient {
  private apiKey: string;
  private baseUrl = "https://api.groq.com/openai/v1";

  constructor(apiKey: string) {
    this.apiKey = apiKey;
  }

  async createChatCompletion(options: {
    model: string;
    messages: Array<{ role: string; content: string }>;
    response_format?: { type: string };
  }) {
    try {
      // Map to llama model on Groq
      // Default to llama-3.3-70b-versatile
      const model = options.model === "mistral-large-latest" ? "llama-3.3-70b-versatile" : options.model;
      
      const response = await axios.post(
        `${this.baseUrl}/chat/completions`,
        {
          model,
          messages: options.messages,
          response_format: options.response_format,
        },
        {
          headers: {
            "Authorization": `Bearer ${this.apiKey}`,
            "Content-Type": "application/json",
          },
        }
      );

      return {
        choices: [
          {
            message: {
              content: response.data.choices[0].message.content,
            },
          },
        ],
      };
    } catch (error) {
      console.error("Error calling Groq API:", error);
      throw error;
    }
  }
}

// Initialize the Groq client
export const mistral = new GroqClient(process.env.GROQ_API_KEY || "");

export async function analyzePRDiff(diff: string): Promise<CodeAnalysisResult> {
  const response = await mistral.createChatCompletion({
    model: "llama-3.3-70b-versatile",
    messages: [
      {
        role: "system",
        content: `You are an expert code reviewer. Analyze the provided code diff and return a JSON object with:
        - score: 0-100 based on overall quality
        - securityIssues: array of security concerns
        - performanceIssues: array of performance issues
        - maintainabilityIssues: array of maintainability concerns
        - summary: human readable summary of changes
        Each issue should have a title, description, and severity (low, medium, high)`
      },
      {
        role: "user",
        content: diff
      }
    ],
    response_format: { type: "json_object" }
  });

  const content = response.choices[0].message.content;
  if (!content) {
    throw new Error("No response from Mistral");
  }

  return JSON.parse(content) as CodeAnalysisResult;
}

export function generatePRComment(analysis: CodeAnalysisResult): string {
  const issueToMd = (issues: Record<string, any>[], type: string) => {
    if (issues.length === 0) return '';
    return `
### ${type} Issues
${issues.map(i => `- **${i.title}** (${i.severity})
  ${i.description}`).join('\n')}
`;
  };

  return `# AI Code Review Summary

Overall Score: ${analysis.score}/100

${analysis.summary}

${issueToMd(analysis.securityIssues, 'Security')}
${issueToMd(analysis.performanceIssues, 'Performance')}
${issueToMd(analysis.maintainabilityIssues, 'Maintainability')}

---
*Generated by BaseSync AI Code Review (Mistral via Groq)*`;
}

// Chat support
export async function getChatResponse(message: string): Promise<string> {
  try {
    const response = await mistral.createChatCompletion({
      model: "llama-3.3-70b-versatile",
      messages: [
        {
          role: "system",
          content: "You are a helpful code assistant. Provide clear, concise, and accurate responses about code, development practices, and technical concepts. When appropriate, include code examples."
        },
        {
          role: "user",
          content: message
        }
      ]
    });

    const reply = response.choices[0].message.content;
    if (!reply) {
      throw new Error("No response from Mistral");
    }

    return reply;
  } catch (error) {
    console.error("Error in Mistral chat:", error);
    throw error;
  }
}
